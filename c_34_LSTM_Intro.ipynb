{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CssNwFfgY5LB"
   },
   "source": [
    "# LSTM 소개\n",
    "- 코랩에서 실행해야 함\n",
    "- 기본 LSTM\n",
    "- Stacked LSTM\n",
    "- Bidirectional LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "70oH617kY5LE"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXBQH_ErY6HM"
   },
   "source": [
    "## 시계열 데이터를 테이블 구조로 바꾸는 함수\n",
    "- n_steps: LSTM 모델이 과거 몇개의 입력을 고려할지를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3wPd1qnLzqLu"
   },
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "  X, y = [],[]\n",
    "  for i in range(len(sequence)):\n",
    "    end_ix = i + n_steps\n",
    "    if end_ix > len(sequence)-1:\n",
    "      break\n",
    "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "  return array(X), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5EKdjBQGZ3W"
   },
   "source": [
    "- 시계열 데이터를 테이블 구조로 바꾸는 예\n",
    "- 간단한 데이터로 LSTM 모델을 만드는 방법을 설명하겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzpD7mWnUnom",
    "outputId": "6597819e-dabd-4821-c0e4-f5e3821f16ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[10, 20, 30],\n",
       "        [20, 30, 40],\n",
       "        [30, 40, 50],\n",
       "        [40, 50, 60],\n",
       "        [50, 60, 70],\n",
       "        [60, 70, 80]]), array([40, 50, 60, 70, 80, 90]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "n_steps = 3\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-_7WrJCZTg8"
   },
   "source": [
    "### LSTM 모델은 [samples, timesteps, features] 구조의 입력을 사용\n",
    "- 2차원이 아니라, 3차원 구조의 데이터가 필요하다\n",
    "\n",
    "- samples: 샘플수\n",
    "- timesteps: n_steps를 말함\n",
    "- features: 한 입력의 특성수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3paiw96Uz_8",
    "outputId": "7a34345c-0505-4d13-bd59-c43a17b5b5d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10],\n",
       "        [20],\n",
       "        [30]],\n",
       "\n",
       "       [[20],\n",
       "        [30],\n",
       "        [40]],\n",
       "\n",
       "       [[30],\n",
       "        [40],\n",
       "        [50]],\n",
       "\n",
       "       [[40],\n",
       "        [50],\n",
       "        [60]],\n",
       "\n",
       "       [[50],\n",
       "        [60],\n",
       "        [70]],\n",
       "\n",
       "       [[60],\n",
       "        [70],\n",
       "        [80]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h43YJi0ZZrdv"
   },
   "source": [
    "\n",
    "## 기본 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKRUIShjzqLv",
    "outputId": "ca6b61ae-b2ea-49f8-b7a8-a0d096f0c5d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[[102.36681]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(20, activation='relu', input_shape=(n_steps, n_features))) \n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYs5cCz1Y5LK",
    "outputId": "0aa5bd03-39ad-4fa5-dbb4-37c5fae00218"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[70],\n",
       "        [80],\n",
       "        [90]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fuOpia7xWB_h",
    "outputId": "528df698-5763-4b71-bd4f-e39dfedbb229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000.0344]]\n"
     ]
    }
   ],
   "source": [
    "# 샘플 입력 예\n",
    "x_input = array([700, 800, 900])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZ5LTENeY5LP"
   },
   "source": [
    "## Stacked LSTM\n",
    "\n",
    "- LSTM을 2개의 레이어로 구성하는 경우\n",
    "- 첫번째 레이어에서 return_sequences=True 옵션을 지정해야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdEglAPlZvv8"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykCx9ugKY5LQ",
    "outputId": "0942efc4-631c-46f0-8b03-3ae11a8d2ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[[102.854485]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(20, activation='relu', return_sequences=True, \n",
    "               input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(20, activation='relu')) \n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features)) \n",
    "yhat = model.predict(x_input, verbose=0) \n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oKZ3sVzY5LT"
   },
   "source": [
    "## Bidirectional LSTM\n",
    "- 양방향으로 학습한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iV3wPm62Y5LU",
    "outputId": "5f34b317-7614-4a89-8537-d75dec89470f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[[101.38728]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(20, activation='relu'), \n",
    "                        input_shape=(n_steps, n_features))) \n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "c_34_LSTM_Intro.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "301.448px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
