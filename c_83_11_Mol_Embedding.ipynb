{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzpae9-r2aoK"
      },
      "source": [
        "# Embeddings for Molecules\n",
        "\n",
        "- use a `SeqToSeq` model to generate fingerprints for classifying molecules.  \n",
        "\n",
        "- [Seq2seq Fingerprint: An Unsupervised Deep Molecular Embedding for Drug Discovery](https://doi.org/10.1145/3107411.3107424).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import"
      ],
      "metadata": {
        "id": "kX9HOIX1T6vD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uo2i6arBiMS",
        "outputId": "09f70d42-be17-4cad-b247-fdd068b6fa0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepchem\n",
            "  Downloading deepchem-2.6.1-py3-none-any.whl (608 kB)\n",
            "\u001b[K     |████████████████████████████████| 608 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.8 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi->deepchem) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->deepchem) (3.1.0)\n",
            "Installing collected packages: rdkit-pypi, deepchem\n",
            "Successfully installed deepchem-2.6.1 rdkit-pypi-2022.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre deepchem\n",
        "import deepchem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem as dc\n",
        "from deepchem.models.optimizers import Adam, ExponentialDecay"
      ],
      "metadata": {
        "id": "Lo70fFiJU4hH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bm1iYbw2aoT"
      },
      "source": [
        "# Learning Embeddings with SeqToSeq\n",
        "\n",
        "- Many types of models require their inputs to have a fixed shape.  But molecules can vary widely in the numbers of atoms and bonds \n",
        "- We need a way of generating a fixed length \"fingerprint\" for each molecule.  \n",
        " - Extended-Connectivity Fingerprints (ECFPs) we used in earlier tutorials.  \n",
        " - instead of designing a fingerprint by hand, we will let a `SeqToSeq` model learn its own method of creating fingerprints.\n",
        "\n",
        "- A `SeqToSeq` model \n",
        " - often used to translate text from one language to another.  \n",
        " - The encoder is a stack of recurrent layers  and generates a fixed length vector called the \"embedding vector\".  \n",
        " - The decoder is another stack of recurrent layers that performs the inverse operation: it takes the embedding vector as input, and generates the output sequence.  \n",
        " - By training it on appropriately chosen input/output pairs, you can create a model that performs many sorts of transformations.\n",
        "\n",
        "- We will use SMILES strings describing molecules as the input sequences.  We will train the model as an autoencoder, so it tries to make the output sequences identical to the input sequences.  \n",
        " - The encoder must create embedding vectors that contain all information from the original sequence.  \n",
        " - That's exactly what we want in a fingerprint, so perhaps those embedding vectors will then be useful as a way to represent molecules in other models!\n",
        "\n",
        "- Use the MUV dataset.  It includes 74,501 molecules in the training set, and 9313 molecules in the validation set, so it gives us plenty of SMILES strings to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YnAnjl9d2aoU"
      },
      "outputs": [],
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_muv(splitter='stratified')\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "train_smiles = train_dataset.ids\n",
        "valid_smiles = valid_dataset.ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EslVHE2m2aoY"
      },
      "source": [
        "- We need to define the \"alphabet\" for our `SeqToSeq` model, the list of all tokens that can appear in sequences. \n",
        "- Make a list of every character that appears in any training sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nsE8e9xn2aoa"
      },
      "outputs": [],
      "source": [
        "tokens = set()\n",
        "for s in train_smiles:\n",
        "  tokens = tokens.union(set(c for c in s))\n",
        "tokens = sorted(list(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF1rFbUK-RuX",
        "outputId": "7e8fbd67-fd0d-4966-a8c7-b7d7a7674b7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#', '(', ')', '+', '-', '/', '1', '2', '3', '4']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tokens[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWOjDkegHQu6",
        "outputId": "8a5861ca-178c-4ffc-a7f3-cb8614e7498f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(tasks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgzyJ1-42aog"
      },
      "source": [
        "- Use `ExponentialDecay` to multiply the learning rate by 0.9 after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NHKrymnM2aoh"
      },
      "outputs": [],
      "source": [
        "max_length = max(len(s) for s in train_smiles)\n",
        "batch_size = 100\n",
        "batches_per_epoch = len(train_smiles)/batch_size\n",
        "model = dc.models.SeqToSeq(tokens,\n",
        "                           tokens,\n",
        "                           max_length,\n",
        "                           encoder_layers=2,\n",
        "                           decoder_layers=2,\n",
        "                           embedding_dimension=256,\n",
        "                           model_dir='fingerprint',\n",
        "                           batch_size=batch_size,\n",
        "                           learning_rate=ExponentialDecay(0.001, 0.9, batches_per_epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSr7FkSW2aok"
      },
      "source": [
        "- The input to `fit_sequences()` is a generator that produces input/output pairs.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NZ5l_g1E2aok"
      },
      "outputs": [],
      "source": [
        "def generate_sequences(epochs):\n",
        "  for i in range(epochs):\n",
        "    for s in train_smiles:\n",
        "      yield (s, s)\n",
        "\n",
        "model.fit_sequences(generate_sequences(40)) # epoch: 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lxf1lmX2aoo"
      },
      "source": [
        "- We'll run the first 500 molecules from the validation set through it, and see how many of them are exactly reproduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXDBtIvn2aop",
        "outputId": "4650bdd3-9f9b-4a4c-b4fa-4302ba913b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reproduced 165 of 500 validation SMILES strings\n"
          ]
        }
      ],
      "source": [
        "predicted = model.predict_from_sequences(valid_smiles[:500])\n",
        "count = 0\n",
        "for s,p in zip(valid_smiles[:500], predicted):\n",
        "  if ''.join(p) == s:\n",
        "    count += 1\n",
        "print('reproduced', count, 'of 500 validation SMILES strings')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt9GLy502aou"
      },
      "source": [
        "- Now we'll trying using the encoder as a way to generate molecular fingerprints.  \n",
        "- We compute the embedding vectors for all molecules in the training and validation datasets, and create new datasets that have those as their feature vectors.  \n",
        "- The amount of data is small enough that we can just store everything in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kdUfsbtZ2aov"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train_embeddings = model.predict_embeddings(train_smiles)\n",
        "train_embeddings_dataset = dc.data.NumpyDataset(train_embeddings,\n",
        "                                                train_dataset.y,\n",
        "                                                train_dataset.w.astype(np.float32),\n",
        "                                                train_dataset.ids)\n",
        "\n",
        "valid_embeddings = model.predict_embeddings(valid_smiles)\n",
        "valid_embeddings_dataset = dc.data.NumpyDataset(valid_embeddings,\n",
        "                                                valid_dataset.y,\n",
        "                                                valid_dataset.w.astype(np.float32),\n",
        "                                                valid_dataset.ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVvfGr562aoz"
      },
      "source": [
        "For classification, we'll use a simple fully connected network with one hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFmnnVNm2aoz",
        "outputId": "091082f3-c79d-4a41-8265-8ca704d0558c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10887121200561524"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "classifier = dc.models.MultitaskClassifier(n_tasks=len(tasks),\n",
        "                                                      n_features=256,\n",
        "                                                      layer_sizes=[512])\n",
        "classifier.fit(train_embeddings_dataset, nb_epoch=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khdB2v7R2ao2"
      },
      "source": [
        "Find out how well it worked.  Compute the ROC AUC for the training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlilhPvm2ao2",
        "outputId": "600224f4-02cd-42a4-f306-cdd14d9d29fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set ROC AUC: {'mean-roc_auc_score': 0.9815878005141317}\n",
            "Validation set ROC AUC: {'mean-roc_auc_score': 0.7945280315147936}\n"
          ]
        }
      ],
      "source": [
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "train_score = classifier.evaluate(train_embeddings_dataset, [metric], transformers)\n",
        "valid_score = classifier.evaluate(valid_embeddings_dataset, [metric], transformers)\n",
        "print('Training set ROC AUC:', train_score)\n",
        "print('Validation set ROC AUC:', valid_score)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "c_83_11_Mol_Embedding.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}